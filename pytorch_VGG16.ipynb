{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_trainable(model, requires_grad):\n",
    "\tfor param in model.parameters():\n",
    "\t\tparam.requires_grad = requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    \"\"\" Architecture defination for VGG \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(3, 64, 3, same_padding=True),\n",
    "                                  nn.Conv2d(64, 64, 3, same_padding=True),\n",
    "                                  nn.MaxPool2d((2)))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(64, 128, 3, same_padding=True),\n",
    "                                  nn.Conv2d(128, 128, 3, same_padding=True),\n",
    "                                  nn.MaxPool2d((2)))\n",
    "        \n",
    "        # we will not train cnv1 and conv2 layer \n",
    "        set_trainable(self.conv1, requires_grad=False)\n",
    "        set_trainable(self.conv2, requires_grad=False)\n",
    "\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(64, 128, 3, same_padding=True),\n",
    "                          nn.Conv2d(128, 128, 3, same_padding=True),\n",
    "                          nn.MaxPool2d((2)))\n",
    "        \n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(128, 256, 3, same_padding=True),\n",
    "                  nn.Conv2d(256, 256, 3, same_padding=True),\n",
    "                  nn.MaxPool2d((2)))\n",
    "        self.conv5 = nn.Sequential(nn.Conv2d(256, 512, 3, same_padding=True),\n",
    "          nn.Conv2d(512, 512, 3, same_padding=True),\n",
    "          nn.MaxPool2d((2)))\n",
    "        \n",
    "    def forward(self, im_data):\n",
    "        x = self.conv1(im_data)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        return x\n",
    "    \n",
    "    def load_from_npz(self, params):\n",
    "        d = self.state_dict()\n",
    "        for name, val in d.items():\n",
    "            i,j = int(name[4]), int(name[6]) + 1\n",
    "            ptype = 'weights' if name[-1] == 't' else biases \n",
    "            key = 'conv{}_{}/{}:0'.format(i,j, ptype)\n",
    "            param = torch.from_numpy(params[key])\n",
    "            if ptype == 'weights':\n",
    "                param  = param.permute(3, 2, 0, 1)\n",
    "            val.copy_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
