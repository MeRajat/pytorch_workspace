{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import numpy as np \n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import cv2\n",
    "import os \n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = \"/home/rajat/rajat/fastai/dogscats/sample/train/cats/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Data Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class data_loader(Dataset):\n",
    "    def __init__(self, path, transform=False, file_suffix = \"*.jpg\", label = None, batch_size = 32):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.files = glob.glob(os.path.join(path ,\"*.jpg\"))\n",
    "        self.transform = transform\n",
    "        self.label = torch.cuda.LongTensor(label)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.files[idx]\n",
    "        img = cv2.imread(img_name)\n",
    "        img = cv2.resize(img, dsize = (200,200))\n",
    "        img = np.einsum('ijk->kij', img)\n",
    "        img = np.expand_dims(img, axis =0)\n",
    "        img = torch.from_numpy(img)\n",
    "#         img = torch.FloatTensor(img)\n",
    "        d = {'image'  : img, 'name' : img_name, 'label' : self.label }\n",
    "        return d\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loader = data_loader(path = model_path, label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN (\n",
       "  (conv1): Sequential (\n",
       "    (0): Conv2d(3, 20, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (conv2): Sequential (\n",
       "    (0): Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (conv3): Sequential (\n",
       "    (0): Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (fc): Linear (42320 -> 2)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_conv_block(input_size, output_size, stride_conv=1, stride_pool=2, kernel_size_conv=3, kernel_size_pool=2):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(input_size, output_size, kernel_size=(kernel_size_conv, kernel_size_conv), stride=stride_conv),\n",
    "        nn.BatchNorm2d(output_size),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=kernel_size_pool, stride=2 )\n",
    "    )\n",
    "        \n",
    "    \n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "        This implements basic cnn module\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes = 2):\n",
    "        super().__init__()\n",
    "        self.conv1 = return_conv_block(input_size=3, output_size=20)\n",
    "        self.conv2 = return_conv_block(input_size=20, output_size=40)\n",
    "        self.conv3 = return_conv_block(input_size=40, output_size=80)\n",
    "        self.fc = nn.Linear(23 * 23 * 80, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = out.view(out.size(0), -1) # Flatten the output for linear layer \n",
    "        return self.fc(out)\n",
    "    \n",
    "cnn = CNN()\n",
    "cnn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 200, 200])\n",
      "torch.Size([1, 80, 23, 23])\n",
      "torch.Size([1, 42320])\n",
      "torch.Size([1, 3, 200, 200])\n",
      "torch.Size([1, 80, 23, 23])\n",
      "torch.Size([1, 42320])\n",
      "torch.Size([1, 3, 200, 200])\n",
      "torch.Size([1, 80, 23, 23])\n",
      "torch.Size([1, 42320])\n",
      "torch.Size([1, 3, 200, 200])\n",
      "torch.Size([1, 80, 23, 23])\n",
      "torch.Size([1, 42320])\n",
      "torch.Size([1, 3, 200, 200])\n",
      "torch.Size([1, 80, 23, 23])\n",
      "torch.Size([1, 42320])\n",
      "torch.Size([1, 3, 200, 200])\n",
      "torch.Size([1, 80, 23, 23])\n",
      "torch.Size([1, 42320])\n",
      "torch.Size([1, 3, 200, 200])\n",
      "torch.Size([1, 80, 23, 23])\n",
      "torch.Size([1, 42320])\n",
      "torch.Size([1, 3, 200, 200])\n",
      "torch.Size([1, 80, 23, 23])\n",
      "torch.Size([1, 42320])\n",
      "torch.Size([1, 3, 200, 200])\n",
      "torch.Size([1, 80, 23, 23])\n",
      "torch.Size([1, 42320])\n",
      "torch.Size([1, 3, 200, 200])\n",
      "torch.Size([1, 80, 23, 23])\n",
      "torch.Size([1, 42320])\n",
      "torch.Size([1, 3, 200, 200])\n",
      "torch.Size([1, 80, 23, 23])\n",
      "torch.Size([1, 42320])\n",
      "torch.Size([1, 3, 200, 200])\n",
      "torch.Size([1, 80, 23, 23])\n",
      "torch.Size([1, 42320])\n",
      "torch.Size([1, 3, 200, 200])\n",
      "torch.Size([1, 80, 23, 23])\n",
      "torch.Size([1, 42320])\n",
      "torch.Size([1, 3, 200, 200])\n",
      "torch.Size([1, 80, 23, 23])\n",
      "torch.Size([1, 42320])\n",
      "torch.Size([1, 3, 200, 200])\n",
      "torch.Size([1, 80, 23, 23])\n",
      "torch.Size([1, 42320])\n",
      "torch.Size([1, 3, 200, 200])\n",
      "torch.Size([1, 80, 23, 23])\n",
      "torch.Size([1, 42320])\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "num_epoch = 2\n",
    "for epoch in range(num_epoch):\n",
    "    for k, d in enumerate(loader):\n",
    "        img = d['image']\n",
    "        label = d['label']\n",
    "        img = Variable(img).cuda()\n",
    "        label = Variable(label).cuda()\n",
    "        # optimize initialize zero grad \n",
    "        optimizer.zero_grad()\n",
    "        output = cnn(img.float())\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = np.arange(20).reshape(2,5,2)\n",
    "a = np.expand_dims(img, axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 5, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
